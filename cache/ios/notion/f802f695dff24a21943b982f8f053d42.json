{
  "ID": "f802f695-dff2-4a21-943b-982f8f053d42",
  "Root": {
    "alive": true,
    "content": [
      "cc54a8ff-d6b4-45b0-a00c-c8e1d0771098",
      "c80c8737-6853-4f91-8f40-674016f62d99",
      "7ea73eb4-bb89-45e0-ae8c-8d3ec7861c69",
      "f1d855ce-b122-48ab-a3bb-b6d5ebc418b4",
      "35c153f7-2717-4dd3-9d11-9e3e295730ce",
      "30e80bb7-8856-4d68-8849-1cf24eeccfd7",
      "1e238fc4-994b-4f45-9f70-0749e5543b3c",
      "dd98171d-d331-4d1a-beb3-bb44a534a97c",
      "b50b500a-cf1d-43e7-ae8c-49e0753d6637",
      "7d6005e8-33a8-4b6a-ac24-7a0dc0413372",
      "fdde9221-8632-49c4-b7d5-10beadb588e3"
    ],
    "created_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
    "created_time": 1550440635006,
    "format": {
      "page_full_width": true,
      "page_small_text": true
    },
    "id": "f802f695-dff2-4a21-943b-982f8f053d42",
    "ignore_block_count": true,
    "last_edited_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
    "last_edited_time": 1550712120000,
    "parent_id": "4d0bc171-666d-4011-91cc-35ada0815e6c",
    "parent_table": "block",
    "properties": {
      "title": [
        [
          "Face and Feature Detection"
        ]
      ]
    },
    "type": "page",
    "version": 8,
    "content_resolved": [
      {
        "alive": true,
        "created_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "created_time": 1550440635001,
        "id": "cc54a8ff-d6b4-45b0-a00c-c8e1d0771098",
        "ignore_block_count": true,
        "last_edited_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "last_edited_time": 1550440635001,
        "parent_id": "f802f695-dff2-4a21-943b-982f8f053d42",
        "parent_table": "block",
        "properties": {
          "title": [
            [
              "Objective-C",
              [
                [
                  "b"
                ]
              ]
            ]
          ]
        },
        "type": "text",
        "version": 1,
        "inline_content": [
          {
            "Text": "Objective-C",
            "AttrFlags": 1
          }
        ]
      },
      {
        "alive": true,
        "created_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "created_time": 1550440635004,
        "id": "c80c8737-6853-4f91-8f40-674016f62d99",
        "ignore_block_count": true,
        "last_edited_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "last_edited_time": 1550440635004,
        "parent_id": "f802f695-dff2-4a21-943b-982f8f053d42",
        "parent_table": "block",
        "properties": {
          "title": [
            [
              "Import the following to your ViewController"
            ]
          ]
        },
        "type": "text",
        "version": 1,
        "inline_content": [
          {
            "Text": "Import the following to your ViewController"
          }
        ]
      },
      {
        "alive": true,
        "created_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "created_time": 1550440635004,
        "id": "7ea73eb4-bb89-45e0-ae8c-8d3ec7861c69",
        "ignore_block_count": true,
        "last_edited_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "last_edited_time": 1550440635004,
        "parent_id": "f802f695-dff2-4a21-943b-982f8f053d42",
        "parent_table": "block",
        "properties": {
          "language": [
            [
              "Plain Text"
            ]
          ],
          "title": [
            [
              "#import \u003cCoreImage/CoreImage.h\u003e\n#import \u003cCoreImage/CoreImage.h\u003e\n#import \u003cQuartzCore/QuartzCore.h\u003e"
            ]
          ]
        },
        "type": "code",
        "version": 1,
        "code": "#import \u003cCoreImage/CoreImage.h\u003e\n#import \u003cCoreImage/CoreImage.h\u003e\n#import \u003cQuartzCore/QuartzCore.h\u003e",
        "code_language": "Plain Text"
      },
      {
        "alive": true,
        "created_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "created_time": 1550440635005,
        "id": "f1d855ce-b122-48ab-a3bb-b6d5ebc418b4",
        "ignore_block_count": true,
        "last_edited_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "last_edited_time": 1550440635005,
        "parent_id": "f802f695-dff2-4a21-943b-982f8f053d42",
        "parent_table": "block",
        "properties": {
          "title": [
            [
              "Call the function"
            ]
          ]
        },
        "type": "text",
        "version": 1,
        "inline_content": [
          {
            "Text": "Call the function"
          }
        ]
      },
      {
        "alive": true,
        "created_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "created_time": 1550440635005,
        "id": "35c153f7-2717-4dd3-9d11-9e3e295730ce",
        "ignore_block_count": true,
        "last_edited_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "last_edited_time": 1550440635005,
        "parent_id": "f802f695-dff2-4a21-943b-982f8f053d42",
        "parent_table": "block",
        "properties": {
          "language": [
            [
              "Plain Text"
            ]
          ],
          "title": [
            [
              "[self faceDetector];"
            ]
          ]
        },
        "type": "code",
        "version": 1,
        "code": "[self faceDetector];",
        "code_language": "Plain Text"
      },
      {
        "alive": true,
        "created_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "created_time": 1550440635005,
        "id": "30e80bb7-8856-4d68-8849-1cf24eeccfd7",
        "ignore_block_count": true,
        "last_edited_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "last_edited_time": 1550440635005,
        "parent_id": "f802f695-dff2-4a21-943b-982f8f053d42",
        "parent_table": "block",
        "properties": {
          "title": [
            [
              "Function definition:"
            ]
          ]
        },
        "type": "text",
        "version": 1,
        "inline_content": [
          {
            "Text": "Function definition:"
          }
        ]
      },
      {
        "alive": true,
        "created_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "created_time": 1550440635005,
        "id": "1e238fc4-994b-4f45-9f70-0749e5543b3c",
        "ignore_block_count": true,
        "last_edited_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "last_edited_time": 1550440635005,
        "parent_id": "f802f695-dff2-4a21-943b-982f8f053d42",
        "parent_table": "block",
        "properties": {
          "language": [
            [
              "Plain Text"
            ]
          ],
          "title": [
            [
              "-(void)faceDetector\n{\n    // Load the picture for face detection\n    UIImageView* image = [[UIImageView alloc] initWithImage:[UIImage imageNamed:@\"download.jpeg\"]];\n    \n    // Draw the face detection image\n    [self.view addSubview:image];\n    \n    // Execute the method used to markFaces in background\n    [self performSelectorInBackground:@selector(markFaces:) withObject:image];\n    \n    // flip image on y-axis to match coordinate system used by core image\n    [image setTransform:CGAffineTransformMakeScale(1, -1)];\n    \n    // flip the entire window to make everything right side up\n    [self.view setTransform:CGAffineTransformMakeScale(1, -1)];\n    \n    \n}"
            ]
          ]
        },
        "type": "code",
        "version": 1,
        "code": "-(void)faceDetector\n{\n    // Load the picture for face detection\n    UIImageView* image = [[UIImageView alloc] initWithImage:[UIImage imageNamed:@\"download.jpeg\"]];\n    \n    // Draw the face detection image\n    [self.view addSubview:image];\n    \n    // Execute the method used to markFaces in background\n    [self performSelectorInBackground:@selector(markFaces:) withObject:image];\n    \n    // flip image on y-axis to match coordinate system used by core image\n    [image setTransform:CGAffineTransformMakeScale(1, -1)];\n    \n    // flip the entire window to make everything right side up\n    [self.view setTransform:CGAffineTransformMakeScale(1, -1)];\n    \n    \n}",
        "code_language": "Plain Text"
      },
      {
        "alive": true,
        "created_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "created_time": 1550440635005,
        "id": "dd98171d-d331-4d1a-beb3-bb44a534a97c",
        "ignore_block_count": true,
        "last_edited_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "last_edited_time": 1550440635005,
        "parent_id": "f802f695-dff2-4a21-943b-982f8f053d42",
        "parent_table": "block",
        "properties": {
          "title": [
            [
              "Mark Face Function"
            ]
          ]
        },
        "type": "text",
        "version": 1,
        "inline_content": [
          {
            "Text": "Mark Face Function"
          }
        ]
      },
      {
        "alive": true,
        "created_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "created_time": 1550440635005,
        "id": "b50b500a-cf1d-43e7-ae8c-49e0753d6637",
        "ignore_block_count": true,
        "last_edited_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "last_edited_time": 1550440635005,
        "parent_id": "f802f695-dff2-4a21-943b-982f8f053d42",
        "parent_table": "block",
        "properties": {
          "language": [
            [
              "Plain Text"
            ]
          ],
          "title": [
            [
              "//Adds face squares and color masks to eyes and mouth\n-(void)markFaces:(UIImageView *)facePicture\n{\n    // draw a CI image with the previously loaded face detection picture\n    CIImage* image = [CIImage imageWithCGImage:facePicture.image.CGImage];\n    \n    // create a face detector - since speed is not an issue we'll use a high accuracy\n    // detector\n    CIDetector* detector = [CIDetector detectorOfType:CIDetectorTypeFace\n                                              context:nil options:[NSDictionary dictionaryWithObject:CIDetectorAccuracyHigh forKey:CIDetectorAccuracy]];\n    \n    // create an array containing all the detected faces from the detector\n    NSArray* features = [detector featuresInImage:image];\n    NSLog(@\"Number of faces %d\",[features count]);\n    \n    // we'll iterate through every detected face.  CIFaceFeature provides us\n    // with the width for the entire face, and the coordinates of each eye\n    // and the mouth if detected.  Also provided are BOOL's for the eye's and\n    // mouth so we can check if they already exist.\n    //    for (features in image)\n    //    {\n    for(CIFaceFeature* faceFeature in features)\n    {\n        // get the width of the face\n        CGFloat faceWidth = faceFeature.bounds.size.width;\n        \n        // create a UIView using the bounds of the face\n        UIView* faceView = [[UIView alloc] initWithFrame:faceFeature.bounds];\n        \n        // add a border around the newly created UIView\n        faceView.layer.borderWidth = 1;\n        faceView.layer.borderColor = [[UIColor redColor] CGColor];\n        \n        // add the new view to create a box around the face\n        [self.view addSubview:faceView];\n        \n        if(faceFeature.hasLeftEyePosition)\n        {\n            // create a UIView with a size based on the width of the face\n            UIView* leftEyeView = [[UIView alloc] initWithFrame:CGRectMake(faceFeature.leftEyePosition.x-faceWidth*0.15, faceFeature.leftEyePosition.y-faceWidth*0.15, faceWidth*0.3, faceWidth*0.3)];\n            // change the background color of the eye view\n            [leftEyeView setBackgroundColor:[[UIColor blueColor] colorWithAlphaComponent:0.3]];\n            // set the position of the leftEyeView based on the face\n            [leftEyeView setCenter:faceFeature.leftEyePosition];\n            // round the corners\n            leftEyeView.layer.cornerRadius = faceWidth*0.15;\n            // add the view to the window\n            [self.view addSubview:leftEyeView];\n        }\n        \n        if(faceFeature.hasRightEyePosition)\n        {\n            // create a UIView with a size based on the width of the face\n            UIView* leftEye = [[UIView alloc] initWithFrame:CGRectMake(faceFeature.rightEyePosition.x-faceWidth*0.15, faceFeature.rightEyePosition.y-faceWidth*0.15, faceWidth*0.3, faceWidth*0.3)];\n            // change the background color of the eye view\n            [leftEye setBackgroundColor:[[UIColor blueColor] colorWithAlphaComponent:0.3]];\n            // set the position of the rightEyeView based on the face\n            [leftEye setCenter:faceFeature.rightEyePosition];\n            // round the corners\n            leftEye.layer.cornerRadius = faceWidth*0.15;\n            // add the new view to the window\n            [self.view addSubview:leftEye];\n        }\n        \n        if(faceFeature.hasMouthPosition)\n        {\n            // create a UIView with a size based on the width of the face\n            UIView* mouth = [[UIView alloc] initWithFrame:CGRectMake(faceFeature.mouthPosition.x-faceWidth*0.2, faceFeature.mouthPosition.y-faceWidth*0.2, faceWidth*0.4, faceWidth*0.4)];\n            // change the background color for the mouth to green\n            [mouth setBackgroundColor:[[UIColor greenColor] colorWithAlphaComponent:0.3]];\n            // set the position of the mouthView based on the face\n            [mouth setCenter:faceFeature.mouthPosition];\n            // round the corners\n            mouth.layer.cornerRadius = faceWidth*0.2;\n            // add the new view to the window\n            [self.view addSubview:mouth];\n        }\n    }\n    \n    // }\n}"
            ]
          ]
        },
        "type": "code",
        "version": 1,
        "code": "//Adds face squares and color masks to eyes and mouth\n-(void)markFaces:(UIImageView *)facePicture\n{\n    // draw a CI image with the previously loaded face detection picture\n    CIImage* image = [CIImage imageWithCGImage:facePicture.image.CGImage];\n    \n    // create a face detector - since speed is not an issue we'll use a high accuracy\n    // detector\n    CIDetector* detector = [CIDetector detectorOfType:CIDetectorTypeFace\n                                              context:nil options:[NSDictionary dictionaryWithObject:CIDetectorAccuracyHigh forKey:CIDetectorAccuracy]];\n    \n    // create an array containing all the detected faces from the detector\n    NSArray* features = [detector featuresInImage:image];\n    NSLog(@\"Number of faces %d\",[features count]);\n    \n    // we'll iterate through every detected face.  CIFaceFeature provides us\n    // with the width for the entire face, and the coordinates of each eye\n    // and the mouth if detected.  Also provided are BOOL's for the eye's and\n    // mouth so we can check if they already exist.\n    //    for (features in image)\n    //    {\n    for(CIFaceFeature* faceFeature in features)\n    {\n        // get the width of the face\n        CGFloat faceWidth = faceFeature.bounds.size.width;\n        \n        // create a UIView using the bounds of the face\n        UIView* faceView = [[UIView alloc] initWithFrame:faceFeature.bounds];\n        \n        // add a border around the newly created UIView\n        faceView.layer.borderWidth = 1;\n        faceView.layer.borderColor = [[UIColor redColor] CGColor];\n        \n        // add the new view to create a box around the face\n        [self.view addSubview:faceView];\n        \n        if(faceFeature.hasLeftEyePosition)\n        {\n            // create a UIView with a size based on the width of the face\n            UIView* leftEyeView = [[UIView alloc] initWithFrame:CGRectMake(faceFeature.leftEyePosition.x-faceWidth*0.15, faceFeature.leftEyePosition.y-faceWidth*0.15, faceWidth*0.3, faceWidth*0.3)];\n            // change the background color of the eye view\n            [leftEyeView setBackgroundColor:[[UIColor blueColor] colorWithAlphaComponent:0.3]];\n            // set the position of the leftEyeView based on the face\n            [leftEyeView setCenter:faceFeature.leftEyePosition];\n            // round the corners\n            leftEyeView.layer.cornerRadius = faceWidth*0.15;\n            // add the view to the window\n            [self.view addSubview:leftEyeView];\n        }\n        \n        if(faceFeature.hasRightEyePosition)\n        {\n            // create a UIView with a size based on the width of the face\n            UIView* leftEye = [[UIView alloc] initWithFrame:CGRectMake(faceFeature.rightEyePosition.x-faceWidth*0.15, faceFeature.rightEyePosition.y-faceWidth*0.15, faceWidth*0.3, faceWidth*0.3)];\n            // change the background color of the eye view\n            [leftEye setBackgroundColor:[[UIColor blueColor] colorWithAlphaComponent:0.3]];\n            // set the position of the rightEyeView based on the face\n            [leftEye setCenter:faceFeature.rightEyePosition];\n            // round the corners\n            leftEye.layer.cornerRadius = faceWidth*0.15;\n            // add the new view to the window\n            [self.view addSubview:leftEye];\n        }\n        \n        if(faceFeature.hasMouthPosition)\n        {\n            // create a UIView with a size based on the width of the face\n            UIView* mouth = [[UIView alloc] initWithFrame:CGRectMake(faceFeature.mouthPosition.x-faceWidth*0.2, faceFeature.mouthPosition.y-faceWidth*0.2, faceWidth*0.4, faceWidth*0.4)];\n            // change the background color for the mouth to green\n            [mouth setBackgroundColor:[[UIColor greenColor] colorWithAlphaComponent:0.3]];\n            // set the position of the mouthView based on the face\n            [mouth setCenter:faceFeature.mouthPosition];\n            // round the corners\n            mouth.layer.cornerRadius = faceWidth*0.2;\n            // add the new view to the window\n            [self.view addSubview:mouth];\n        }\n    }\n    \n    // }\n}",
        "code_language": "Plain Text"
      },
      {
        "alive": true,
        "created_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "created_time": 1550440635005,
        "id": "7d6005e8-33a8-4b6a-ac24-7a0dc0413372",
        "ignore_block_count": true,
        "last_edited_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "last_edited_time": 1550440635005,
        "parent_id": "f802f695-dff2-4a21-943b-982f8f053d42",
        "parent_table": "block",
        "properties": {
          "title": [
            [
              "The Simulator ScreenShot for the Function"
            ]
          ]
        },
        "type": "text",
        "version": 1,
        "inline_content": [
          {
            "Text": "The Simulator ScreenShot for the Function"
          }
        ]
      },
      {
        "alive": true,
        "created_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "created_time": 1550440635005,
        "id": "fdde9221-8632-49c4-b7d5-10beadb588e3",
        "ignore_block_count": true,
        "last_edited_by": "bb760e2d-d679-4b64-b2a9-03005b21870a",
        "last_edited_time": 1550440635005,
        "parent_id": "f802f695-dff2-4a21-943b-982f8f053d42",
        "parent_table": "block",
        "properties": {
          "source": [
            [
              "http://i.stack.imgur.com/AAvQS.png"
            ]
          ]
        },
        "type": "image",
        "version": 1,
        "source": "http://i.stack.imgur.com/AAvQS.png",
        "image_url": "https://www.notion.so/image/https:%2F%2Fwww.notion.sohttp:%2F%2Fi.stack.imgur.com%2FAAvQS.png"
      }
    ],
    "title": "Face and Feature Detection",
    "format_page": {
      "page_cover": "",
      "page_cover_position": 0,
      "page_font": "",
      "page_full_width": true,
      "page_icon": "",
      "page_small_text": true
    }
  },
  "Users": [
    {
      "email": "kkowalczyk@gmail.com",
      "family_name": "Kowalczyk",
      "given_name": "Krzysztof",
      "id": "bb760e2d-d679-4b64-b2a9-03005b21870a",
      "locale": "en",
      "mobile_onboarding_completed": true,
      "onboarding_completed": true,
      "profile_photo": "https://s3-us-west-2.amazonaws.com/public.notion-static.com/2dcaa66c-7674-4ff6-9924-601785b63561/head-bw-640x960.png",
      "time_zone": "America/Los_Angeles",
      "version": 18
    }
  ],
  "Tables": null
}